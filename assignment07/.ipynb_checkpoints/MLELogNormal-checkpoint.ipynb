{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLE for Log-Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you will perform [maximum likelihood estimation](https://en.wikipedia.org/wiki/Maximum_likelihood), or MLE, for the parameters in the [log-normal](https://en.wikipedia.org/wiki/Log-normal_distribution) distribution and bootstrap the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your exercise is to perform the following steps in this notebook:\n",
    "\n",
    "* Find the probability density function, $P(x \\mid \\theta)$, with $\\theta=\\left[\\mu,\\sigma^2\\right]$, for a single variate on Wikipedia and typeset it into a markdown cell. In that same markdown cell, compose a few sentences that describes the equation and defines all of its symbols.\n",
    "* Work out the log-likelihood, $ln\\mathcal{L}(\\theta \\mid x)$, and typeset it into another markdown cell. In that same markdown cell, compose a few sentences that describes the equation and defines all of its symbols.\n",
    "* For known values of the parameters $\\mu=0.5$ and $\\sigma^2=1.0$, generate an array of `50` random variates.\n",
    "* Make an appropriately labeled Seaborn `distplot` of your dataset.\n",
    "* Write a Python function, `neg_log_llh(theta, data)`, that returns the negative log-likelihood for the full dataset and estimated $\\hat{\\theta}=\\left[\\hat{\\mu},\\hat{\\sigma}^2\\right]$.\n",
    "* Use `interact` to print the value of the negative log-likelihood with one slider each for $\\hat{\\mu}$ and $\\hat{\\sigma}^2$. Find the values of $\\hat{\\mu}$ and $\\hat{\\sigma}^2$ that minimize the negative log-likelihood by simply moving the sliders around. Write some text in a markdown cell that summarizes your findings.\n",
    "* Write a function, `mle(data)`, that uses `scipy.optimize.minimize` to find the estimated parameters $\\hat{\\theta}$ that minimize the negative log-likelihood for the data.\n",
    "* Bootstrap your dataset and compute bootstrapped $\\hat{\\theta}$ distributions. Plot your $\\hat{\\theta}$ distribution using a Seaborn `jointplot`. Be very careful about making this distribution plot, paying close attention to the limits of the plot and outliers.\n",
    "* Follow [PEP8](https://www.python.org/dev/peps/pep-0008/) and write a properly formatted [docstring](https://github.com/numpy/numpy/blob/master/doc/HOWTO_DOCUMENT.rst.txt) for all of your functions.\n",
    "* Add additional markdown cells that describe your code and results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the known, master parameters to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mu = 0.5\n",
    "sigma2 = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell will be used for grading!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
