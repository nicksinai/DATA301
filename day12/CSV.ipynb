{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working With CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Objectives:** Learn how to import and export data as CSV files using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A CSV file is a simple textual format:\n",
    "\n",
    "* One row per line\n",
    "* Column values separated a comma, space, etc.\n",
    "* CSV = \"comma separated value\"\n",
    "\n",
    "CSV files are one of the most universal and common formats for distributing table based data across programming languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A CSV file with no header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple CSV file that doesn't have a header that declares the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data1.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile data1.csv\n",
    "one,76,3.4\n",
    "two,74,5.6\n",
    "three,73,2.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at its contents by using the `%pycat` magic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0mone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m76\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3.4\u001b[0m\u001b[1;33m\u001b[0m\n",
       "\u001b[1;33m\u001b[0m\u001b[0mtwo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m74\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5.6\u001b[0m\u001b[1;33m\u001b[0m\n",
       "\u001b[1;33m\u001b[0m\u001b[0mthree\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m73\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2.9\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pycat data1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV files can be read into Pandas `DataFrame` objects using the `read_csv` function. Here is the documentation for `read_csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature: \u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdialect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'infer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mescapechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquotechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\"'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquoting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipinitialspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlineterminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'infer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipfooter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_footer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfalse_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconverters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelim_whitespace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_recarray\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_filter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompact_ints\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_unsigned\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_default_na\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthousands\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mb'.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_date_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdayfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate_parser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat_precision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmangle_dupe_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtupleize_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_blank_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Read CSV (comma-separated) file into DataFrame\n",
       "\n",
       "Also supports optionally iterating or breaking of the file\n",
       "into chunks.\n",
       "\n",
       "Additional help can be found in the `online docs for IO Tools\n",
       "<http://pandas.pydata.org/pandas-docs/stable/io.html>`_.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "filepath_or_buffer : string or file handle / StringIO\n",
       "    The string could be a URL. Valid URL schemes include\n",
       "    http, ftp, s3, and file. For file URLs, a\n",
       "    host is expected. For instance, a local file could be\n",
       "    file ://localhost/path/to/table.csv\n",
       "sep : string, default ','\n",
       "    Delimiter to use. If sep is None, will try to automatically determine\n",
       "    this. Regular expressions are accepted.\n",
       "engine : {'c', 'python'}\n",
       "    Parser engine to use. The C engine is faster while the python engine is\n",
       "    currently more feature-complete.\n",
       "lineterminator : string (length 1), default None\n",
       "    Character to break file into lines. Only valid with C parser\n",
       "quotechar : string (length 1)\n",
       "    The character used to denote the start and end of a quoted item. Quoted\n",
       "    items can include the delimiter and it will be ignored.\n",
       "quoting : int or csv.QUOTE_* instance, default None\n",
       "    Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
       "    QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
       "    Default (None) results in QUOTE_MINIMAL behavior.\n",
       "skipinitialspace : boolean, default False\n",
       "    Skip spaces after delimiter\n",
       "escapechar : string (length 1), default None\n",
       "    One-character string used to escape delimiter when quoting is QUOTE_NONE.\n",
       "dtype : Type name or dict of column -> type, default None\n",
       "    Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32}\n",
       "    (Unsupported with engine='python')\n",
       "compression : {'gzip', 'bz2', 'infer', None}, default 'infer'\n",
       "    For on-the-fly decompression of on-disk data. If 'infer', then use gzip or\n",
       "    bz2 if filepath_or_buffer is a string ending in '.gz' or '.bz2',\n",
       "    respectively, and no decompression otherwise. Set to None for no\n",
       "    decompression.\n",
       "dialect : string or csv.Dialect instance, default None\n",
       "    If None defaults to Excel dialect. Ignored if sep longer than 1 char\n",
       "    See csv.Dialect documentation for more details\n",
       "header : int, list of ints, default 'infer'\n",
       "    Row number(s) to use as the column names, and the start of the\n",
       "    data.  Defaults to 0 if no ``names`` passed, otherwise ``None``. Explicitly\n",
       "    pass ``header=0`` to be able to replace existing names. The header can be\n",
       "    a list of integers that specify row locations for a multi-index on the\n",
       "    columns E.g. [0,1,3]. Intervening rows that are not specified will be\n",
       "    skipped (e.g. 2 in this example are skipped). Note that this parameter\n",
       "    ignores commented lines and empty lines if ``skip_blank_lines=True``, so header=0\n",
       "    denotes the first line of data rather than the first line of the file.\n",
       "skiprows : list-like or integer, default None\n",
       "    Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
       "    at the start of the file\n",
       "index_col : int or sequence or False, default None\n",
       "    Column to use as the row labels of the DataFrame. If a sequence is given, a\n",
       "    MultiIndex is used. If you have a malformed file with delimiters at the end\n",
       "    of each line, you might consider index_col=False to force pandas to _not_\n",
       "    use the first column as the index (row names)\n",
       "names : array-like, default None\n",
       "    List of column names to use. If file contains no header row, then you\n",
       "    should explicitly pass header=None\n",
       "prefix : string, default None\n",
       "    Prefix to add to column numbers when no header, e.g 'X' for X0, X1, ...\n",
       "na_values : str, list-like or dict, default None\n",
       "    Additional strings to recognize as NA/NaN. If dict passed, specific\n",
       "    per-column NA values\n",
       "true_values : list, default None\n",
       "    Values to consider as True\n",
       "false_values : list, default None\n",
       "    Values to consider as False\n",
       "keep_default_na : bool, default True\n",
       "    If na_values are specified and keep_default_na is False the default NaN\n",
       "    values are overridden, otherwise they're appended to\n",
       "parse_dates : boolean, list of ints or names, list of lists, or dict, default False\n",
       "    If True -> try parsing the index.\n",
       "    If [1, 2, 3] -> try parsing columns 1, 2, 3 each as a separate date column.\n",
       "    If [[1, 3]] -> combine columns 1 and 3 and parse as a single date column.\n",
       "    {'foo' : [1, 3]} -> parse columns 1, 3 as date and call result 'foo'\n",
       "    A fast-path exists for iso8601-formatted dates.\n",
       "keep_date_col : boolean, default False\n",
       "    If True and parse_dates specifies combining multiple columns then\n",
       "    keep the original columns.\n",
       "date_parser : function, default None\n",
       "    Function to use for converting a sequence of string columns to an\n",
       "    array of datetime instances. The default uses dateutil.parser.parser\n",
       "    to do the conversion. Pandas will try to call date_parser in three different\n",
       "    ways, advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
       "    (as defined by parse_dates) as arguments; 2) concatenate (row-wise) the string\n",
       "    values from the columns defined by parse_dates into a single array and pass\n",
       "    that; and 3) call date_parser once for each row using one or more strings\n",
       "    (corresponding to the columns defined by parse_dates) as arguments.\n",
       "dayfirst : boolean, default False\n",
       "    DD/MM format dates, international and European format\n",
       "thousands : str, default None\n",
       "    Thousands separator\n",
       "comment : str, default None\n",
       "    Indicates remainder of line should not be parsed. If found at the\n",
       "    beginning of a line, the line will be ignored altogether. This parameter\n",
       "    must be a single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
       "    fully commented lines are ignored by the parameter `header`\n",
       "    but not by `skiprows`. For example, if comment='#', parsing\n",
       "    '#empty\\na,b,c\\n1,2,3' with `header=0` will result in 'a,b,c' being\n",
       "    treated as the header.\n",
       "decimal : str, default '.'\n",
       "    Character to recognize as decimal point. E.g. use ',' for European data\n",
       "nrows : int, default None\n",
       "    Number of rows of file to read. Useful for reading pieces of large files\n",
       "iterator : boolean, default False\n",
       "    Return TextFileReader object for iteration or getting chunks with ``get_chunk()``.\n",
       "chunksize : int, default None\n",
       "    Return TextFileReader object for iteration. `See IO Tools docs for more\n",
       "    information\n",
       "    <http://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_ on\n",
       "    ``iterator`` and ``chunksize``.\n",
       "skipfooter : int, default 0\n",
       "    Number of lines at bottom of file to skip (Unsupported with engine='c')\n",
       "converters : dict, default None\n",
       "    Dict of functions for converting values in certain columns. Keys can either\n",
       "    be integers or column labels\n",
       "verbose : boolean, default False\n",
       "    Indicate number of NA values placed in non-numeric columns\n",
       "delimiter : string, default None\n",
       "    Alternative argument name for sep. Regular expressions are accepted.\n",
       "encoding : string, default None\n",
       "    Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
       "    standard encodings\n",
       "    <https://docs.python.org/3/library/codecs.html#standard-encodings>`_\n",
       "squeeze : boolean, default False\n",
       "    If the parsed data only contains one column then return a Series\n",
       "na_filter : boolean, default True\n",
       "    Detect missing value markers (empty strings and the value of na_values). In\n",
       "    data without any NAs, passing na_filter=False can improve the performance\n",
       "    of reading a large file\n",
       "usecols : array-like, default None\n",
       "    Return a subset of the columns.\n",
       "    Results in much faster parsing time and lower memory usage.\n",
       "mangle_dupe_cols : boolean, default True\n",
       "    Duplicate columns will be specified as 'X.0'...'X.N', rather than 'X'...'X'\n",
       "tupleize_cols : boolean, default False\n",
       "    Leave a list of tuples on columns as is (default is to convert to\n",
       "    a Multi Index on the columns)\n",
       "error_bad_lines : boolean, default True\n",
       "    Lines with too many fields (e.g. a csv line with too many commas) will by\n",
       "    default cause an exception to be raised, and no DataFrame will be returned.\n",
       "    If False, then these \"bad lines\" will dropped from the DataFrame that is\n",
       "    returned. (Only valid with C parser)\n",
       "warn_bad_lines : boolean, default True\n",
       "    If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
       "    \"bad line\" will be output. (Only valid with C parser).\n",
       "infer_datetime_format : boolean, default False\n",
       "    If True and parse_dates is enabled for a column, attempt to infer\n",
       "    the datetime format to speed up the processing\n",
       "skip_blank_lines : boolean, default True\n",
       "    If True, skip over blank lines rather than interpreting as NaN values\n",
       "\n",
       "Returns\n",
       "-------\n",
       "result : DataFrame or TextParser\n",
       "\u001b[1;31mFile:      \u001b[0m/usr/local/lib/python3.4/dist-packages/pandas/io/parsers.py\n",
       "\u001b[1;31mType:      \u001b[0mfunction"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually the first step is to try reading the file with no extra arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one</th>\n",
       "      <th>76</th>\n",
       "      <th>3.4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>two</td>\n",
       "      <td>74</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>three</td>\n",
       "      <td>73</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     one  76  3.4\n",
       "0    two  74  5.6\n",
       "1  three  73  2.9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we don't want the first row to be treated as the column index, so we pass `header=None`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>76</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>two</td>\n",
       "      <td>74</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>three</td>\n",
       "      <td>73</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1    2\n",
       "0    one  76  3.4\n",
       "1    two  74  5.6\n",
       "2  three  73  2.9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data1.csv', header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pass our own names for the column names, pass the `name` argument. If the number of names matches the number of columns, an integer index will be created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>temp</th>\n",
       "      <th>rainfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>76</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>two</td>\n",
       "      <td>74</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>three</td>\n",
       "      <td>73</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    item  temp  rainfall\n",
       "0    one    76       3.4\n",
       "1    two    74       5.6\n",
       "2  three    73       2.9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data1.csv', header=None, names=['item','temp','rainfall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if we pass fewer names than columns, the first column will be used as the row index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>rainfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>76</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>74</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>73</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       temp  rainfall\n",
       "one      76       3.4\n",
       "two      74       5.6\n",
       "three    73       2.9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data1.csv', header=None, names=['temp','rainfall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `index_col` argument to specify which column to use as the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>rainfall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>one</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>two</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>three</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item  rainfall\n",
       "temp                 \n",
       "76      one       3.4\n",
       "74      two       5.6\n",
       "73    three       2.9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data1.csv', header=None, names=['item','temp','rainfall'], index_col=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A CSV file with a header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a CSV file that has a heade giving default column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data2.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile data2.csv\n",
    "Person,Age,Income,Zip\n",
    "one,20,55000,95050\n",
    "two,24,65000,95054\n",
    "three,26,75000,95014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, `read_csv` will use those as the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>Zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>20</td>\n",
       "      <td>55000</td>\n",
       "      <td>95050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>two</td>\n",
       "      <td>24</td>\n",
       "      <td>65000</td>\n",
       "      <td>95054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>three</td>\n",
       "      <td>26</td>\n",
       "      <td>75000</td>\n",
       "      <td>95014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Person  Age  Income    Zip\n",
       "0    one   20   55000  95050\n",
       "1    two   24   65000  95054\n",
       "2  three   26   75000  95014"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To override the column names, you can provide a `names` argument and `header=0`. If there are one fewer names that columns the first column will be used as the index. Or you can use `index_col` to specify which column is used as an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>20</td>\n",
       "      <td>55000</td>\n",
       "      <td>95050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>24</td>\n",
       "      <td>65000</td>\n",
       "      <td>95054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>26</td>\n",
       "      <td>75000</td>\n",
       "      <td>95014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  income    zip\n",
       "one     20   55000  95050\n",
       "two     24   65000  95054\n",
       "three   26   75000  95014"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data2.csv', names=['age','income','zip'], header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of a CSV files with missing and non-tidy data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data3.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile data3.csv\n",
    "age,income,zip\n",
    "32,NA,95050\n",
    "-1,4500,\n",
    ",50000,95054\n",
    "24,NULL,0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default `read_csv` automatically converts missing values and certain (`NA`, `NULL`, `-1`) values to NaNs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>4500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>50000</td>\n",
       "      <td>95054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  income    zip\n",
       "0   32     NaN  95050\n",
       "1   -1    4500    NaN\n",
       "2  NaN   50000  95054\n",
       "3   24     NaN      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `na_values` argument can be used to specify additional values for all columns that will be treated as NaNs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>4500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>50000</td>\n",
       "      <td>95054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  income    zip\n",
       "0   32     NaN  95050\n",
       "1   -1    4500    NaN\n",
       "2  NaN   50000  95054\n",
       "3   24     NaN    NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data3.csv', na_values=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can pass `na_values` a ditionary providing NaN sentinals for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>50000</td>\n",
       "      <td>95054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  income    zip\n",
       "0   32     NaN  95050\n",
       "1  NaN    4500    NaN\n",
       "2  NaN   50000  95054\n",
       "3   24     NaN    NaN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data3.csv', na_values={'zip':[0,'NULL'], 'age': [-1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pandas [CSV Documentation](http://pandas.pydata.org/pandas-docs/stable/io.html#csv-text-files)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
